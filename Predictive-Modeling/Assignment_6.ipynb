{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe2b390c",
   "metadata": {},
   "source": [
    "### Blake Pritchard\n",
    "### DTSC-680\n",
    "### Assignment-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b49b0d",
   "metadata": {},
   "source": [
    "## Mushroom Classification\n",
    "\n",
    "we will attempt to build a model which can determine whether a mushroom specimen is edible, based upon the quantifiable metrics observed in our mushroom database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61262bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up notebook dependencies\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cd19e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate encoder objects\n",
    "\n",
    "encoder_OneHot_impute = OneHotEncoder()\n",
    "encoder_Labels_impute = LabelEncoder()\n",
    "\n",
    "encoder_OneHot_inference = OneHotEncoder()\n",
    "encoder_Labels_inference = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79eb1b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Column Names \n",
    "\n",
    "def get_column_names():\n",
    "    return ['edible',\n",
    "            'cap-shape',\n",
    "            'cap-surface',\n",
    "            'cap-color',\n",
    "            'bruises',\n",
    "            'odor',\n",
    "            'gill-attachment',\n",
    "            'gill-spacing',\n",
    "            'gill-size',\n",
    "            'gill-color',\n",
    "            'stalk-shape',\n",
    "            'stalk-root',\n",
    "            'stalk-surface-above-ring',\n",
    "            'stalk-surface-below-ring',\n",
    "            'stalk-color-above-ring',\n",
    "            'stalk-color-below-ring',\n",
    "            'veil-type',\n",
    "            'veil-color',\n",
    "            'ring-number',\n",
    "            'ring-type',\n",
    "            'spore-print-color',\n",
    "            'population',\n",
    "            'habitat'\n",
    "           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c69c76",
   "metadata": {},
   "source": [
    "---\n",
    "### Read Mushroom data from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5314ff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_column_names = get_column_names()\n",
    "mushroom_data = pd.read_csv('agaricus-lepiota.data', header=None, names=a_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1286ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_rows_complete = mushroom_data['stalk-root'] != '?'\n",
    "index_rows_incomplete = mushroom_data['stalk-root'] == '?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fb53cd",
   "metadata": {},
   "source": [
    "---\n",
    "### Use KNN to Impute missing values\n",
    "\n",
    "We will start by separating the columsninto features ans labels\n",
    "fot this imputation step we want to predict the values of the 'stalk-root'.\n",
    "therefore, our label will be the \"stalk-root' and our features will be everything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c93b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_training_labels = mushroom_data['stalk-root']\n",
    "impute_training_features = mushroom_data.loc[:, mushroom_data.columns != 'stalk-root']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8a3827",
   "metadata": {},
   "source": [
    "Encode Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4531aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_labels_Encoded = encoder_Labels_impute.fit_transform(impute_training_labels)\n",
    "impute_features_OneHot = encoder_OneHot_impute.fit_transform(impute_training_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2627806",
   "metadata": {},
   "source": [
    "\n",
    "Next build an Index of Rows which Require Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d5e98bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_training_labels_complete = impute_labels_Encoded[index_rows_complete]\n",
    "impute_training_features_complete = impute_features_OneHot[index_rows_complete]\n",
    "impute_predict_features_incomplete = impute_features_OneHot[index_rows_incomplete]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1149110",
   "metadata": {},
   "source": [
    "Train KNN Classifier on Encoded Copy of Complete Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afdf6830",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier()\n",
    "trained_imputation_model = classifier.fit(impute_training_features_complete, impute_training_labels_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581ff476",
   "metadata": {},
   "source": [
    "Impute Missing Values Based on Encoded Copy of Incomplete Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbe30c7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blake/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "missing_values_encoded = trained_imputation_model.predict(impute_predict_features_incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9cee6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = encoder_Labels_impute.inverse_transform(missing_values_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ab5ca5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['b', 'c', 'e'], dtype=object), array([1891,   65,  524]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(missing_values, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d877d706",
   "metadata": {},
   "source": [
    "### Review Value Counts\n",
    "\n",
    "We can review the counts of each missing value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2654df3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['b' 1891]\n",
      " ['c' 65]\n",
      " ['e' 524]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(missing_values, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "214b7b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'e', 'b', 'b',\n",
       "       'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e',\n",
       "       'b', 'b', 'b', 'b', 'e', 'b', 'e', 'b', 'e', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'e', 'e', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b',\n",
       "       'e', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b',\n",
       "       'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'e', 'b', 'e',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'e', 'e', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'c', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'e', 'b', 'b', 'b', 'e',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b',\n",
       "       'b', 'b', 'e', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'e', 'e', 'e', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'e',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'e',\n",
       "       'b', 'e', 'b', 'b', 'b', 'b', 'b', 'e', 'e', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'e', 'e', 'b', 'e', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'e', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'e', 'b', 'b',\n",
       "       'e', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'c', 'b', 'e', 'b', 'b', 'b', 'e', 'b',\n",
       "       'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'e', 'b', 'b', 'b',\n",
       "       'e', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'e', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e',\n",
       "       'b', 'b', 'b', 'e', 'b', 'b', 'e', 'b', 'b', 'b', 'e', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'e', 'b', 'b', 'b', 'e',\n",
       "       'b', 'e', 'b', 'b', 'c', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'e', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'e', 'b',\n",
       "       'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'e', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'e', 'e', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'e', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'e', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'e', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'e', 'e',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'e', 'e', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'e', 'b', 'e', 'e', 'b', 'b', 'b', 'e',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'c', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b',\n",
       "       'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'e', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'e',\n",
       "       'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'e', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'e', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b',\n",
       "       'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'e', 'b', 'e', 'b', 'b', 'e', 'b', 'b', 'e', 'b', 'b', 'b',\n",
       "       'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'e', 'e',\n",
       "       'e', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'e', 'e', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'e', 'b', 'b', 'b', 'b', 'c', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'e', 'b', 'b', 'e', 'b', 'e', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'e', 'b', 'b', 'b', 'b', 'e', 'b', 'e', 'b', 'c', 'b', 'e', 'b',\n",
       "       'b', 'e', 'b', 'b', 'c', 'b', 'b', 'b', 'b', 'b', 'e', 'e', 'b',\n",
       "       'b', 'e', 'b', 'e', 'e', 'b', 'b', 'e', 'c', 'b', 'b', 'b', 'b',\n",
       "       'e', 'c', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'e', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'e', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'c', 'e', 'b', 'b', 'e',\n",
       "       'b', 'b', 'e', 'e', 'e', 'b', 'b', 'b', 'b', 'c', 'e', 'b', 'b',\n",
       "       'b', 'e', 'b', 'c', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'e', 'e',\n",
       "       'b', 'b', 'e', 'e', 'e', 'b', 'b', 'b', 'b', 'b', 'e', 'e', 'e',\n",
       "       'e', 'e', 'b', 'e', 'e', 'e', 'b', 'b', 'e', 'b', 'e', 'b', 'b',\n",
       "       'b', 'b', 'e', 'b', 'b', 'e', 'b', 'b', 'b', 'e', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'e', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'e', 'b',\n",
       "       'b', 'b', 'b', 'b', 'e', 'b', 'e', 'b', 'b', 'b', 'e', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'c', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'e',\n",
       "       'e', 'e', 'e', 'b', 'b', 'b', 'b', 'c', 'b', 'e', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'c', 'b', 'b',\n",
       "       'b', 'b', 'b', 'e', 'b', 'e', 'b', 'b', 'e', 'b', 'b', 'e', 'b',\n",
       "       'b', 'e', 'b', 'b', 'b', 'e', 'b', 'c', 'b', 'b', 'b', 'e', 'e',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'e',\n",
       "       'b', 'e', 'e', 'b', 'b', 'e', 'b', 'b', 'e', 'b', 'b', 'b', 'b',\n",
       "       'e', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'e', 'b', 'e',\n",
       "       'b', 'e', 'e', 'c', 'b', 'e', 'e', 'b', 'e', 'e', 'b', 'b', 'b',\n",
       "       'b', 'e', 'e', 'c', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'e',\n",
       "       'b', 'b', 'e', 'e', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'b',\n",
       "       'e', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'c', 'b', 'b', 'e', 'b',\n",
       "       'b', 'e', 'b', 'b', 'e', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b',\n",
       "       'c', 'e', 'b', 'b', 'b', 'c', 'e', 'b', 'b', 'e', 'b', 'e', 'b',\n",
       "       'b', 'e', 'c', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'e', 'b',\n",
       "       'e', 'c', 'e', 'b', 'b', 'b', 'b', 'c', 'e', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'c', 'b', 'e', 'b', 'b', 'e', 'e', 'b', 'e', 'c', 'b',\n",
       "       'b', 'b', 'e', 'e', 'e', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b',\n",
       "       'e', 'b', 'e', 'e', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'c', 'b',\n",
       "       'e', 'b', 'c', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'e',\n",
       "       'e', 'b', 'e', 'e', 'b', 'c', 'b', 'b', 'b', 'e', 'e', 'e', 'b',\n",
       "       'e', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'e',\n",
       "       'b', 'b', 'e', 'b', 'e', 'b', 'b', 'e', 'b', 'e', 'e', 'b', 'b',\n",
       "       'e', 'b', 'c', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'e', 'b', 'b',\n",
       "       'b', 'c', 'e', 'b', 'e', 'e', 'b', 'b', 'b', 'c', 'c', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'e', 'b', 'b',\n",
       "       'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'e', 'e', 'b',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'e', 'b', 'b', 'e',\n",
       "       'b', 'e', 'b', 'b', 'b', 'b', 'b', 'e', 'e', 'c', 'b', 'e', 'b',\n",
       "       'e', 'e', 'b', 'e', 'e', 'e', 'c', 'e', 'b', 'b', 'e', 'e', 'e',\n",
       "       'e', 'b', 'b', 'b', 'e', 'b', 'c', 'b', 'e', 'b', 'b', 'e', 'b',\n",
       "       'b', 'e', 'e', 'b', 'e', 'b', 'b', 'e', 'b', 'e', 'b', 'e', 'b',\n",
       "       'b', 'e', 'c', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'c', 'b', 'b',\n",
       "       'e', 'b', 'b', 'b', 'b', 'b', 'c', 'b', 'b', 'e', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'e', 'c', 'b', 'c',\n",
       "       'b', 'b', 'e', 'b', 'e', 'e', 'b', 'b', 'b', 'e', 'e', 'b', 'b',\n",
       "       'e', 'e', 'e', 'b', 'e', 'e', 'b', 'b', 'b', 'e', 'b', 'b', 'b',\n",
       "       'e', 'e', 'e', 'e', 'e', 'b', 'b', 'b', 'b', 'e', 'e', 'e', 'e',\n",
       "       'b', 'e', 'b', 'b', 'b', 'e', 'e', 'b', 'b', 'e', 'b', 'c', 'e',\n",
       "       'b', 'b', 'b', 'b', 'b', 'e', 'b', 'e', 'b', 'b', 'b', 'e', 'b',\n",
       "       'e', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'e', 'e', 'b', 'b', 'e',\n",
       "       'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'e', 'b', 'b', 'b', 'e',\n",
       "       'b', 'e', 'b', 'b', 'e', 'b', 'e', 'b', 'e', 'e', 'c', 'c', 'b',\n",
       "       'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'e', 'b', 'e', 'e',\n",
       "       'b', 'e', 'e', 'e', 'e', 'b', 'e', 'e', 'b', 'b', 'e', 'e', 'e',\n",
       "       'b', 'b', 'b', 'b', 'e', 'b', 'e', 'e', 'c', 'b', 'e', 'b', 'b',\n",
       "       'b', 'e', 'e', 'b', 'b', 'b', 'e', 'b', 'e', 'e', 'b', 'b', 'b',\n",
       "       'e', 'b', 'b', 'b', 'b', 'b', 'e', 'e', 'e', 'e', 'b', 'b', 'b',\n",
       "       'e', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'e', 'b', 'e',\n",
       "       'e', 'e', 'b', 'e', 'c', 'b', 'b', 'b', 'c', 'b', 'b', 'b', 'e',\n",
       "       'b', 'e', 'b', 'b', 'e', 'e', 'b', 'e', 'b', 'e', 'e', 'b', 'e',\n",
       "       'b', 'e', 'b', 'e', 'b', 'b', 'e', 'e', 'e', 'b', 'b', 'b', 'b',\n",
       "       'b', 'b', 'b', 'b', 'c', 'b', 'b', 'b', 'b', 'e', 'c', 'b', 'b',\n",
       "       'b', 'b', 'b', 'e', 'e', 'b', 'b', 'c', 'e', 'e', 'b', 'b', 'b',\n",
       "       'b', 'b', 'e', 'b', 'b', 'b', 'e', 'b', 'b', 'b', 'e', 'b', 'b',\n",
       "       'c', 'e', 'e', 'e', 'e', 'e', 'b', 'b', 'b', 'e', 'e', 'e', 'b',\n",
       "       'e', 'b', 'b', 'e', 'b', 'e', 'e', 'e', 'e', 'b', 'e', 'b', 'b',\n",
       "       'e', 'b', 'b', 'e', 'b', 'b', 'b', 'b', 'e', 'e', 'e', 'b', 'b',\n",
       "       'e', 'b', 'b', 'b', 'c', 'c', 'e', 'b', 'b', 'e', 'e', 'b', 'b',\n",
       "       'b', 'b', 'b', 'e', 'c', 'e', 'e', 'e', 'e', 'b', 'e', 'b', 'b',\n",
       "       'b', 'e', 'c', 'b', 'b', 'b', 'e', 'e', 'c', 'b', 'e', 'c', 'c',\n",
       "       'e', 'b', 'e', 'b', 'b', 'b', 'e', 'b', 'c', 'e', 'b', 'b', 'b',\n",
       "       'e', 'e', 'b', 'e', 'b', 'b', 'e', 'c', 'e', 'e', 'b', 'b', 'b',\n",
       "       'b', 'b', 'e', 'e', 'e', 'b', 'e', 'b', 'e', 'b', 'c', 'c', 'e',\n",
       "       'b', 'e', 'b', 'b', 'b', 'e', 'e', 'b', 'b', 'e', 'b', 'b', 'b',\n",
       "       'b', 'e', 'e', 'e', 'b', 'b', 'e', 'b', 'e', 'e', 'e', 'b', 'e',\n",
       "       'b', 'b', 'b', 'b', 'e', 'e', 'b', 'e', 'b', 'e', 'e', 'b', 'b',\n",
       "       'b', 'b', 'b', 'e', 'b', 'e', 'b', 'c', 'e', 'e', 'b', 'e', 'b',\n",
       "       'e', 'b', 'e', 'c', 'e', 'e', 'b', 'b', 'b', 'b', 'b', 'e', 'e',\n",
       "       'e', 'b', 'e', 'b', 'b', 'b', 'b', 'b', 'b', 'e', 'b', 'b', 'e',\n",
       "       'e', 'b', 'e', 'e', 'e', 'e', 'e', 'e', 'b', 'c', 'e', 'e', 'e',\n",
       "       'b', 'e', 'b', 'b', 'b', 'e', 'e', 'e', 'b', 'e'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1e25177",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rows_complete = mushroom_data[index_rows_complete].copy()\n",
    "data_rows_incomplete = mushroom_data[index_rows_incomplete].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9be81e",
   "metadata": {},
   "source": [
    "Here we can examine our target rows before the update.\n",
    "We can see that all these rows are missing data, we use this to get the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cd725af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3984    ?\n",
       "4023    ?\n",
       "4076    ?\n",
       "4100    ?\n",
       "4104    ?\n",
       "       ..\n",
       "8119    ?\n",
       "8120    ?\n",
       "8121    ?\n",
       "8122    ?\n",
       "8123    ?\n",
       "Name: stalk-root, Length: 2480, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rows_incomplete['stalk-root']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a8b13e",
   "metadata": {},
   "source": [
    "#### Create a series with the name of the columns and set the index of the rows\n",
    "we will  copy the index of the incomplete rows so we can insert them back into the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6de7c61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3984    b\n",
       "4023    b\n",
       "4076    e\n",
       "4100    b\n",
       "4104    b\n",
       "       ..\n",
       "8119    e\n",
       "8120    e\n",
       "8121    e\n",
       "8122    b\n",
       "8123    e\n",
       "Name: stalk-root, Length: 2480, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_update = pd.Series(missing_values, name='stalk-root', index=data_rows_incomplete.index)\n",
    "series_update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5440a11",
   "metadata": {},
   "source": [
    "In the main dataset we see there are some rows with data, and some rows which are still missing data with '?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0095fe25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       e\n",
       "1       c\n",
       "2       c\n",
       "3       e\n",
       "4       e\n",
       "       ..\n",
       "8119    ?\n",
       "8120    ?\n",
       "8121    ?\n",
       "8122    ?\n",
       "8123    ?\n",
       "Name: stalk-root, Length: 8124, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mushroom_data['stalk-root']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148d82be",
   "metadata": {},
   "source": [
    "#### Update the imputed values back into the original dataset\n",
    "this works becuase the series object we created includes the column namne and index for the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c96a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "mushroom_data.update(series_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98140077",
   "metadata": {},
   "source": [
    "Finally, we can see that the rows which were missing data, have now been updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9de039c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       e\n",
       "1       c\n",
       "2       c\n",
       "3       e\n",
       "4       e\n",
       "       ..\n",
       "8119    e\n",
       "8120    e\n",
       "8121    e\n",
       "8122    b\n",
       "8123    e\n",
       "Name: stalk-root, Length: 8124, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mushroom_data['stalk-root']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fef2aac",
   "metadata": {},
   "source": [
    "We can verify that there are no longer any '?' values in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15e1f37a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mushroom_data['stalk-root']=='?').any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3445cd2c",
   "metadata": {},
   "source": [
    "# Concept Question 1\n",
    "#### why dont we one-hot encode the respose data to train the KNN model:\n",
    "\n",
    "since one-hot encoding adds a new dimension for each value, and the 'stalk-root' has six different valid values, the encoded result would have six different dimensions.\n",
    "\n",
    "If our labels had multiple dimensions, our problem domain changes from a multi-class, to a multi-label problem;\n",
    "which requires a more complex regression model and significanlty more computing resources to train, without providing any additional value to our solution.\n",
    "\n",
    "In practice even using the LabelBinarizer seems to be incompatible with the KNeighborsClassifier which is returning a set of 4 distinct binary columns:\n",
    "\n",
    "##### ValueError: y should be a 1d array, got an array of shape (2480, 4) instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bebbdc8",
   "metadata": {},
   "source": [
    "---\n",
    "### Create Test and Training Dataset\n",
    "\n",
    "Starting with the updated and re-asembled dataset, we will create a new complete dataset of OneHot Features and LabelEncoded labels for training.\n",
    "\n",
    "This time the label we are predicting is the 'edible' dimension, will be the 'edible' field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82569229",
   "metadata": {},
   "outputs": [],
   "source": [
    "mushroom_labels = mushroom_data['edible']\n",
    "mushroom_features = mushroom_data.loc[:, ((mushroom_data.columns != 'edible')) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50c4afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferencing_labels_Encoded = encoder_Labels_inference.fit_transform(mushroom_labels)\n",
    "inferencing_features_OneHot = encoder_OneHot_inference.fit_transform(mushroom_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5938c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    inferencing_features_OneHot, \n",
    "    inferencing_labels_Encoded, \n",
    "    test_size=0.33,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a18da3",
   "metadata": {},
   "source": [
    "---\n",
    "### Random Forest with Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b167a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8d56815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 377 ms, sys: 3.79 ms, total: 381 ms\n",
      "Wall time: 382 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa232626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[1378    0]\n",
      " [   0 1303]]\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "predictions_random_forest = random_forest.predict(X_test)\n",
    "\n",
    "accuracy_rfc = accuracy_score(y_test, predictions_random_forest)\n",
    "precision_rfc = precision_score(y_test, predictions_random_forest)\n",
    "recall_rfc = recall_score(y_test, predictions_random_forest)\n",
    "\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, predictions_random_forest))\n",
    "print(\"Accuracy: \" + str(accuracy_rfc))\n",
    "print(\"Precision: \" + str(precision_rfc))\n",
    "print(\"Recall: \" + str(recall_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92d49b8",
   "metadata": {},
   "source": [
    "---\n",
    "### Logistic Regression with Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b564682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c946ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 77.8 ms, sys: 1.8 ms, total: 79.6 ms\n",
      "Wall time: 79 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logistic_regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ec3d280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[1378    0]\n",
      " [   0 1303]]\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "predictions_logistic_regression = logistic_regression.predict(X_test)\n",
    "\n",
    "accuracy_lrg = accuracy_score(y_test, predictions_logistic_regression)\n",
    "precision_lrg = precision_score(y_test, predictions_logistic_regression)\n",
    "recall_lrg = recall_score(y_test, predictions_logistic_regression)\n",
    "\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, predictions_logistic_regression))\n",
    "print(\"Accuracy: \" + str(accuracy_lrg))\n",
    "print(\"Precision: \" + str(precision_lrg))\n",
    "print(\"Recall: \" + str(recall_lrg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70cac61",
   "metadata": {},
   "source": [
    "# Concept Question 2\n",
    "#### Could we train these models by one-hot encoding the response data if we dropped the first parameter:\n",
    "\n",
    "\n",
    "Yes, using the LabelBinarizer produces identical results in this case.\n",
    "\n",
    "becuase there are only two potential values for 'edible', then if we one-hot encoded the data and dropped the first parameter, we would end up with a single binary dimension like 'poisonous' = True/False\n",
    "\n",
    "However I was not able to actually make the OneHotEncoder object perform the fit.\n",
    "The OneHotEncoder can return a sparse matrix which makes the RandomForest model throw an error when fitting:\n",
    "###### \"sparse multilabel-indicator for y is not supported\"\n",
    "\n",
    "The scikit-learn documentation for [OneHotEncoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) is clear about this:\n",
    "\n",
    "\"Note: a one-hot encoding of y labels should use a LabelBinarizer instead.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa35624",
   "metadata": {},
   "source": [
    "---\n",
    "### Perform Principal Component Analysis\n",
    "\n",
    "To reduce the number of features, we will fit a PCA model on entire featureset; \n",
    "Then use the trained PCA model to reduce the number dimensions (columns) in X_train and X_test\n",
    "\n",
    "lets examine how many dimensions are in X_train; and we see that there are 116 dimensions to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f16ea95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5443, 116)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7290fdb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=0.95, random_state=42)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "pca.fit(inferencing_features_OneHot.toarray())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ebf1d8",
   "metadata": {},
   "source": [
    "lets examine our PCA model components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50a25952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57b610a",
   "metadata": {},
   "source": [
    "We have reduced the number of encoded features from 116 down to 41.\n",
    "So we have dropped 75 dimensions, which is a reduction of 64.65%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4557132b",
   "metadata": {},
   "source": [
    "Now we will create reduced versions of our original training and test sets.\n",
    "\n",
    "we do this so our next models will train on the exact same records (rows), but fewer features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f18a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced = pca.transform(X_train.toarray())\n",
    "X_test_reduced = pca.transform(X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02613f46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5443, 41)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "198a60c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2681, 41)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a92c15",
   "metadata": {},
   "source": [
    "---\n",
    "### Random Forest Classifier on the Reduced features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf0ec632",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_reduced = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90a39a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.71 s, sys: 2.94 ms, total: 1.71 s\n",
      "Wall time: 1.72 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "random_forest_reduced.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7eb458c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[1378    0]\n",
      " [   0 1303]]\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "predictions_random_forest_reduced = random_forest_reduced.predict(X_test_reduced)\n",
    "\n",
    "accuracy_rfc_reduced = accuracy_score(y_test, predictions_random_forest_reduced)\n",
    "precision_rfc_reduced = precision_score(y_test, predictions_random_forest_reduced)\n",
    "recall_rfc_reduced = recall_score(y_test, predictions_random_forest_reduced)\n",
    "\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, predictions_random_forest_reduced))\n",
    "print(\"Accuracy: \" + str(accuracy_rfc_reduced))\n",
    "print(\"Precision: \" + str(precision_rfc_reduced))\n",
    "print(\"Recall: \" + str(recall_rfc_reduced))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cf5990",
   "metadata": {},
   "source": [
    "---\n",
    "### Logistic Regression against the Reduced features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa602b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_reduced = LogisticRegression() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54126251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 67.6 ms, sys: 4.96 ms, total: 72.6 ms\n",
      "Wall time: 37.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logistic_regression_reduced.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1d66e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[1372    6]\n",
      " [   8 1295]]\n",
      "Accuracy: 0.9947780678851175\n",
      "Precision: 0.9953881629515757\n",
      "Recall: 0.9938603223330775\n"
     ]
    }
   ],
   "source": [
    "predictions_logistic_regression_reduced = logistic_regression_reduced.predict(X_test_reduced)\n",
    "\n",
    "accuracy_lrg_reduced = accuracy_score(y_test, predictions_logistic_regression_reduced)\n",
    "precision_lrg_reduced = precision_score(y_test, predictions_logistic_regression_reduced)\n",
    "recall_lrg_reduced = recall_score(y_test, predictions_logistic_regression_reduced)\n",
    "\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, predictions_logistic_regression_reduced))\n",
    "print(\"Accuracy: \" + str(accuracy_lrg_reduced))\n",
    "print(\"Precision: \" + str(precision_lrg_reduced))\n",
    "print(\"Recall: \" + str(recall_lrg_reduced))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe70a51",
   "metadata": {},
   "source": [
    "| Models | Item | Full Data | PCA Reduced |\n",
    "| :----- | :--- | :-------- | :---------- |\n",
    "| <b> Random Forest </b> | <b> Accuracy </b> | 1.0 | 1.0 |\n",
    "| | <b> Precision </b>| 1.0 | 1.0 |\n",
    "| | <b> Recall </b>| 1.0 | 1.0 |\n",
    "| | <b> Time </b>| 381 ms | 1.71 s |\n",
    "| <b> Logistic Regression </b> | <b> Accuracy </b> | 1.0 | 0.99477 |\n",
    "| | <b> Precision </b>| 1.0 | 0.9953 |\n",
    "| | <b> Recall </b>| 1.0 | 0.9938 |\n",
    "| | <b> Time </b>| 79.6 ms | 72.6 ms |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369195c0",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "I do not entirely understand why the Random Forest model took longer to train on a smaller dataset.\n",
    "\n",
    "I do think it is interesting to see how the RandomForest and LogisticRegression models perform differently when we reduce the dataset.\n",
    "While the RandomForest takes significantly longer to train with reduced data, it still performs with great accuracy.\n",
    "\n",
    "The LogisticRegression model trains just a little faster, but begins to lose accuracy when we reduce the data.\n",
    "\n",
    "It seems like the RandomForest model makes a worthwhile investment of computing resources to spend the additional time and likely producing a more optimal model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
