{"cells":[{"cell_type":"markdown","source":["## Name: Blake Pritchard\n","## Date: 2024-05-25"],"metadata":{"id":"bSuf_gBuNYxj"},"id":"bSuf_gBuNYxj"},{"cell_type":"markdown","id":"51a57afe","metadata":{"id":"51a57afe"},"source":["\n","# Building and Evaluating a Hidden Markov Model and a Viterbi Algorithm in NLP\n","\n","## Overview\n","This exercise aims to guide you through the process of building and evaluating a Hidden Markov Model (HMM) with a Viterbi algorithm in the field of Natural Language Processing (NLP). We will use the Brown corpus from the NLTK library, focusing on the categories 'news', 'editorial', and 'reviews' with a 'universal' tagset. The purpose is to provide practical experience in implementing these fundamental concepts in NLP and to understand their applications and limitations.\n"]},{"cell_type":"markdown","id":"18180696","metadata":{"id":"18180696"},"source":["\n","## Preparing the Environment\n","\n","To set up our NLP environment, we'll first import the necessary libraries. We use NLTK for accessing linguistic data and algorithms, including the Brown corpus, and `train_test_split` from `sklearn.model_selection` for splitting data. The Brown Corpus was the first million-word electronic corpus of English, created in 1961 at Brown University.\n","\n","[Brown Corpus](https://en.wikipedia.org/wiki/Brown_Corpus)\n","\n","This corpus contains text from 500 sources, and the sources have been categorized by genre, such as news, editorial, and so on. We need to download the 'brown' corpus and the 'universal_tagset' using the `nltk.download()` command. Use `nltk.download('brown')` to get the corpus and `nltk.download('universal_tagset')` to obtain a simplified version of the part-of-speech tags.\n","\n","This step ensures we have all necessary components for building and evaluating our models.\n","\n"]},{"cell_type":"code","source":["#!pip install dill"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GR9pVHdwg36v","executionInfo":{"status":"ok","timestamp":1716603045930,"user_tz":300,"elapsed":10111,"user":{"displayName":"Blake Pritchard","userId":"04857546906785525811"}},"outputId":"3f5b7902-06d5-40bc-f48c-c71a67b631c5"},"id":"GR9pVHdwg36v","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting dill\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: dill\n","Successfully installed dill-0.3.8\n"]}]},{"cell_type":"code","source":["import nltk\n","import sklearn\n","import dill"],"metadata":{"id":"ONadZ1qTVf7W"},"id":"ONadZ1qTVf7W","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"045303a7-7e4a-4cf8-a3e5-f2c9bcf34f17","metadata":{"execution":{"iopub.execute_input":"2023-11-23T01:48:05.106154Z","iopub.status.busy":"2023-11-23T01:48:05.106154Z","iopub.status.idle":"2023-11-23T01:48:05.117152Z","shell.execute_reply":"2023-11-23T01:48:05.116159Z","shell.execute_reply.started":"2023-11-23T01:48:05.106154Z"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"045303a7-7e4a-4cf8-a3e5-f2c9bcf34f17","executionInfo":{"status":"ok","timestamp":1716598736779,"user_tz":300,"elapsed":1159,"user":{"displayName":"Blake Pritchard","userId":"04857546906785525811"}},"outputId":"a7e0e4fd-94ec-49af-deb9-5fb9acd5736e"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Package brown is already up-to-date!\n","[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n","[nltk_data]   Package universal_tagset is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}],"source":["nltk.download('brown')\n","nltk.download('universal_tagset')"]},{"cell_type":"code","source":["from nltk.corpus import brown\n","\n","from sklearn.model_selection import train_test_split\n","from nltk.tag import HiddenMarkovModelTrainer"],"metadata":{"id":"_fuxi3oYWEle"},"id":"_fuxi3oYWEle","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"ca04166d-5394-4cf5-83c1-a073dda1c9fe","metadata":{"id":"ca04166d-5394-4cf5-83c1-a073dda1c9fe"},"source":["\n","## Loading and Exploring the Data\n","\n","Load the 'Brown' corpus, focusing on specific categories: 'news', 'editorial', and 'reviews'. We'll use the 'universal' tagset for a more generalizable analysis. Utilize `brown.tagged_sents(categories=['news', 'editorial', 'reviews'], tagset='universal')` to load the data.\n","\n","The **universal** tagset is a simplified schema developed to facilitate the comparison of grammatical categories across different languages. This tagset includes categories like:\n","\n","    NOUN (noun)\n","    VERB (verb)\n","    ADJ (adjective)\n","    ADV (adverb)\n","    PRON (pronoun)\n","    DET (determiner, includes articles and quantifiers)\n","    ADP (adposition, includes prepositions and postpositions)\n","    NUM (numeral)\n","    CONJ (conjunction)\n","    PRT (particle, includes small function words like 'to' that are not clearly categorized under the above)\n","    . (punctuation)\n","    X (other category, including undefined and erroneous cases)\n","\n","The `tagged_sents()` returns a list comprised of sentences, where each sentence is another list of word-tag pairs. Each pair consists of a word from the sentence and its corresponding part-of-speech tag\n","\n","Once loaded, we encourage you to perform an exploratory analysis of the dataset to understand its structure and the nature of the tagged sentences."]},{"cell_type":"code","execution_count":null,"id":"80f5971e-b5ef-4718-ac6d-f949d9f18583","metadata":{"execution":{"iopub.execute_input":"2023-11-23T00:41:32.603334Z","iopub.status.busy":"2023-11-23T00:41:32.603334Z","iopub.status.idle":"2023-11-23T00:41:32.632181Z","shell.execute_reply":"2023-11-23T00:41:32.632181Z","shell.execute_reply.started":"2023-11-23T00:41:32.603334Z"},"tags":[],"id":"80f5971e-b5ef-4718-ac6d-f949d9f18583"},"outputs":[],"source":["brown_tagged_sents = brown.tagged_sents(categories=['news', 'editorial', 'reviews'], tagset='universal')"]},{"cell_type":"markdown","id":"af8bf573","metadata":{"id":"af8bf573"},"source":["\n","## Data Preprocessing\n","\n","For our Hidden Markov Model, it's essential to preprocess the data to ensure consistency and effectiveness. A key preprocessing step is lowercasing the words in our dataset. This step will help in reducing the complexity of the model by treating words with different cases as the same word. Apply lowercasing to each word in the (word, tag) tuples in our dataset.\n","\n","Be sure to keep **the same data structure** after lowercasing.\n","\n"]},{"cell_type":"code","source":["brown_lower = [[(word.lower(), tag) for word, tag in line] for line in brown_tagged_sents]"],"metadata":{"id":"Y1GiPIIDHO7d"},"id":"Y1GiPIIDHO7d","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"43719399-7ec5-4199-9bb3-ed34cf6e57c0","metadata":{"id":"43719399-7ec5-4199-9bb3-ed34cf6e57c0"},"source":["## Split Train and Test\n","\n","Using train_test_split from sklearn, split the dataset from the previous step into train and test sets. Choose the train/test size and whether you want to use random_state or not.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"e15afefb-d468-4023-a554-4feaf172bd08","metadata":{"execution":{"iopub.execute_input":"2023-11-23T00:41:36.918070Z","iopub.status.busy":"2023-11-23T00:41:36.910877Z","iopub.status.idle":"2023-11-23T00:41:36.984396Z","shell.execute_reply":"2023-11-23T00:41:36.984396Z","shell.execute_reply.started":"2023-11-23T00:41:36.918070Z"},"id":"e15afefb-d468-4023-a554-4feaf172bd08"},"outputs":[],"source":["train_data, test_data = train_test_split(brown_lower, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","id":"8efa3d97-3117-4184-8c2c-c3265d34da13","metadata":{"id":"8efa3d97-3117-4184-8c2c-c3265d34da13"},"source":["\n","## Training the Hidden Markov Model with Viterbi\n","\n","Construct a dictionary of words in the form of a python list that includes every unique word found in the training set. Follow the same process for the tags set. Then, consider this important question: Why is it not advisable to build the dictionary/tags set using all words from both the train and test datasets? Keep in mind the concept of [Data Leakage](https://towardsdatascience.com/data-leakage-in-machine-learning-how-it-can-be-detected-and-minimize-the-risk-8ef4e3a97562) while contemplating this.\n"]},{"cell_type":"code","execution_count":null,"id":"d77cf74a-adc2-42e4-9baa-76eaf4b8a0e8","metadata":{"execution":{"iopub.execute_input":"2023-11-23T00:41:36.984396Z","iopub.status.busy":"2023-11-23T00:41:36.984396Z","iopub.status.idle":"2023-11-23T00:41:37.108311Z","shell.execute_reply":"2023-11-23T00:41:37.107613Z","shell.execute_reply.started":"2023-11-23T00:41:36.984396Z"},"tags":[],"id":"d77cf74a-adc2-42e4-9baa-76eaf4b8a0e8"},"outputs":[],"source":["# Create a list of words in the training set\n","words = []\n","for observation in train_data:\n","    for word, tag in observation:\n","        words.append(word)\n","words = list(set(words))\n","\n","# Create a list of tags in the training set\n","tags = []\n","for state in train_data:\n","    for word, tag in state:\n","        tags.append(tag)\n","tags = list(set(tags))"]},{"cell_type":"markdown","id":"0ed34abc-8814-4b55-a2e8-516cb9827131","metadata":{"id":"0ed34abc-8814-4b55-a2e8-516cb9827131"},"source":["For building our Hidden Markov Model (HMM), we will utilize the [`HiddenMarkovModelTrainer`](https://tedboy.github.io/nlps/generated/generated/nltk.HiddenMarkovModelTrainer.html) class from NLTK.  \n","\n","This class encapsulates [**both the HMM and the Viterbi algorithm**](https://www.nltk.org/api/nltk.tag.hmm.html). The Viterbi algorithm is used here to determine the most likely sequence of tags (states) for a given sequence of words (observations), based on the probabilities learned by the HMM. It's essential to import the `HiddenMarkovModelTrainer` from nltk.tag for this purpose.\n","\n","Create an object from the `HiddenMarkovModelTrainer` using the tag set list and the dictionary list created before. This object will be used to train our HMM models.\n","\n","For this assignment, we will train five (yes, five!) different HMM models:\n","\n","- A 'pure' HMM without smoothing (For more about Smoothing, read chapter three of this [thesis](https://digitalscholarship.unlv.edu/cgi/viewcontent.cgi?article=2008&context=thesesdissertations#:~:text=Smoothing%20techniques%20in%20HMM%20will,to%20produce%20more%20accurate%20probabilities.))\n","\n","    Train a model using the HiddenMarkovModelTrainer object (train_supervised method), passing only the 'train' dataset\n","    \n","    \n","- HMM with [LidstoneProbDist](https://en.wikipedia.org/wiki/Additive_smoothing) smoothing and gamma = 0.01\n","\n","     LidstoneProbDist is an implementation of a Lidstone probability distribution, which is a variant of the Laplace distribution. The gamma parameter is the smoothing factor. The value of gamma determines the degree of smoothing applied. It's generally a positive number. A gamma of 1 corresponds to Laplace smoothing (add-one), while values different from 1 indicate different degrees of smoothing\n","     \n","     Train a model using the HiddenMarkovModelTrainer object (train_supervised method), passing the 'train' dataset and\n","     supplied function `lidstone_prob_dist_001`\n","     \n","     \n","- HMM with [LidstoneProbDist](https://en.wikipedia.org/wiki/Additive_smoothing) smoothing and gamma = 0.1\n","    \n","    Same as above, but with different gamma value.\n","\n","    Train a model using the HiddenMarkovModelTrainer object (train_supervised method), passing the 'train' dataset and the suplied function `lidstone_prob_dist_01`\n","    \n","    \n","- HMM with [MLEProbDist (Maximum Likelihood Estimation)](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation)\n","\n","    The basic idea of MLE is to choose the parameters of a model in such a way that the likelihood (probability) of the observed data is maximized. In other words, MLE seeks the parameter values that make the observed data most probable.\n","     \n","    Train a model using the HiddenMarkovModelTrainer object (train_supervised method), passing the 'train' dataset and  the suplied function `MLE_ProbDist`\n","    \n","     \n","- HMM with [ELEProbDist (Expected Likelihood Estimation)](https://machinelearningmastery.com/what-is-maximum-likelihood-estimation-in-machine-learning/)\n","\n","    This method is a form of statistical smoothing, similar to LidstoneProbDist and LaplaceProbDist, but with a slightly different approach.\n","\n","    The idea behind ELE smoothing is to adjust probabilities in a way that balances accuracy in modeling frequently occurring events with the capability to handle rare or unobserved events. In simple terms, ELE smoothing attempts to estimate the probability of future events based on observed frequency, making adjustments to ensure that unobserved events are not given a probability of zero.\n","     \n","    Train a model using the HiddenMarkovModelTrainer object (train_supervised method), passing the 'train' dataset and the suplied function `ELE_ProbDist`\n","\n","\n","Feel free to try any other approach besides those."]},{"cell_type":"code","execution_count":null,"id":"705afa5d-33a1-4070-8eab-74be1093531b","metadata":{"execution":{"iopub.execute_input":"2023-12-28T16:52:30.267052Z","iopub.status.busy":"2023-12-28T16:52:30.263540Z","iopub.status.idle":"2023-12-28T16:52:30.283242Z","shell.execute_reply":"2023-12-28T16:52:30.283242Z","shell.execute_reply.started":"2023-12-28T16:52:30.267052Z"},"id":"705afa5d-33a1-4070-8eab-74be1093531b"},"outputs":[],"source":["from nltk.probability import LidstoneProbDist, MLEProbDist, ELEProbDist\n","\n","def lidstone_prob_dist_001(fd, bins):\n","    return LidstoneProbDist(fd, 0.01)\n","\n","def lidstone_prob_dist_01(fd, bins):\n","    return LidstoneProbDist(fd, 0.1)\n","\n","def MLE_ProbDist(fd, bins):\n","    return MLEProbDist(fd)\n","\n","def ELE_ProbDist(fd, bins):\n","    return ELEProbDist(fd)"]},{"cell_type":"code","execution_count":null,"id":"e5e8c824-bcdb-49eb-a547-f62288ea94fd","metadata":{"execution":{"iopub.execute_input":"2023-11-23T00:41:37.108311Z","iopub.status.busy":"2023-11-23T00:41:37.108311Z","iopub.status.idle":"2023-11-23T00:41:40.142981Z","shell.execute_reply":"2023-11-23T00:41:40.142981Z","shell.execute_reply.started":"2023-11-23T00:41:37.108311Z"},"tags":[],"id":"e5e8c824-bcdb-49eb-a547-f62288ea94fd"},"outputs":[],"source":["# Importing necessary modules from NLTK for HMM training and probability distributions\n","from nltk.tag import HiddenMarkovModelTrainer\n","from nltk.probability import LidstoneProbDist, MLEProbDist, ELEProbDist\n","\n","# Create a HiddenMarkovModelTrainer object\n","hmm_trainer = HiddenMarkovModelTrainer(states=tags, symbols=words)"]},{"cell_type":"code","source":["# Train the model using only the training set\n","pure_hmm = hmm_trainer.train_supervised(train_data)"],"metadata":{"id":"C56Gw-T1cZtr"},"id":"C56Gw-T1cZtr","execution_count":null,"outputs":[]},{"cell_type":"code","source":["hmm_001 = hmm_trainer.train_supervised(train_data, estimator=lidstone_prob_dist_001)"],"metadata":{"id":"ZL0k3jAOpfMp"},"id":"ZL0k3jAOpfMp","execution_count":null,"outputs":[]},{"cell_type":"code","source":["hmm_01 = hmm_trainer.train_supervised(train_data, estimator=lidstone_prob_dist_01)"],"metadata":{"id":"7aIFIVgjpezR"},"id":"7aIFIVgjpezR","execution_count":null,"outputs":[]},{"cell_type":"code","source":["hmm_mle = hmm_trainer.train_supervised(train_data, estimator=MLE_ProbDist)"],"metadata":{"id":"-H8ewoo8pemY"},"id":"-H8ewoo8pemY","execution_count":null,"outputs":[]},{"cell_type":"code","source":["hmm_ele = hmm_trainer.train_supervised(train_data, estimator=ELE_ProbDist)"],"metadata":{"id":"Ce0__jcKpeS7"},"id":"Ce0__jcKpeS7","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"b77509b8-0848-4a26-b5ae-be6d716fcad4","metadata":{"id":"b77509b8-0848-4a26-b5ae-be6d716fcad4"},"source":["## Applying the HMM with Viterbi Algorithm\n","\n","Predict the tags from the 'test' dataset using **each of the models created before**.\n","\n","Use the `best_path` (docs [here](https://www.nltk.org/api/nltk.tag.hmm.html#nltk.tag.hmm.HiddenMarkovModelTagger.best_path)) function from the model. This function is used to predict the most likely sequence of tags for the given sequence of words. The `best_path` takes an unlabelled (without tags) sentence and returns a sequence of predicted tags.\n","\n","Make sure to 'break' the 'test' dataset and use only the sentence (without tags) part."]},{"cell_type":"code","source":["test_sentences = [[word for word, tag in sentence] for sentence in test_data]\n","test_correct_tags = [[tag for word, tag in sentence] for sentence in test_data]"],"metadata":{"id":"Mr4ciC2xhKyY"},"id":"Mr4ciC2xhKyY","execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_tags_pure_hmm = [pure_hmm.best_path(test_sentence) for test_sentence in test_sentences]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eHStKZkHlR1b","executionInfo":{"status":"ok","timestamp":1716598772584,"user_tz":300,"elapsed":18089,"user":{"displayName":"Blake Pritchard","userId":"04857546906785525811"}},"outputId":"6d70f2d9-8c5d-4474-dc1d-0d69032f0ada"},"id":"eHStKZkHlR1b","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:336: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:334: RuntimeWarning: overflow encountered in cast\n","  X[i, j] = self._transitions[si].logprob(self._states[j])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n"]}]},{"cell_type":"code","source":["predicted_tags_hmm_001 = [hmm_001.best_path(test_sentence) for test_sentence in test_sentences]"],"metadata":{"id":"2LV0rwKKOnax"},"id":"2LV0rwKKOnax","execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_tags_hmm_001 = [hmm_001.best_path(test_sentence) for test_sentence in test_sentences]"],"metadata":{"id":"LUzkarWqhEtP"},"id":"LUzkarWqhEtP","execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_tags_hmm_01 = [hmm_01.best_path(test_sentence) for test_sentence in test_sentences]"],"metadata":{"id":"b_EH_kcIhEiq"},"id":"b_EH_kcIhEiq","execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_tags_hmm_mle = [hmm_mle.best_path(test_sentence) for test_sentence in test_sentences]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lACm4xhmhEZb","executionInfo":{"status":"ok","timestamp":1716598846043,"user_tz":300,"elapsed":19054,"user":{"displayName":"Blake Pritchard","userId":"04857546906785525811"}},"outputId":"a98da160-ecb9-4c5b-dbd9-72f6abcde51d"},"id":"lACm4xhmhEZb","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:336: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:334: RuntimeWarning: overflow encountered in cast\n","  X[i, j] = self._transitions[si].logprob(self._states[j])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n","/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n","  O[i, k] = self._output_logprob(si, self._symbols[k])\n"]}]},{"cell_type":"code","source":["predicted_tags_hmm_ele = [hmm_ele.best_path(test_sentence) for test_sentence in test_sentences]"],"metadata":{"id":"e6vFlCOYi_Ss"},"id":"e6vFlCOYi_Ss","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"2062661a-cfd1-43c3-a023-cd84fabb4e12","metadata":{"tags":[],"id":"2062661a-cfd1-43c3-a023-cd84fabb4e12"},"source":["\n","## Model Evaluation\n","\n","It's essential to evaluate the performance of our HMM equipped with the Viterbi algorithm to gauge how effectively it handles unseen data. This involves comparing the tags predicted by our model on the test dataset against the actual tags.\n","\n","* Utilize the provided `printConlleval` function to compute Precision, Recall, and F1-score for each tag and the overall model.\n","\n","* Utilize the provided `printConfusionMatrix` function to print a confusion matrix that provides insights into the types of errors made by the model and helps in evaluating the accuracy of predictions\n","\n","**IMPORTANT:** Both functions require a list comprised of sentences, where each sentence is a another list of word-tag pair. Example:\n","\n","    'labels_predicted' and 'labels_correct' format:\n","    \n","    [[('conservation', 'NOUN'), ('plan', 'NOUN')],\n","     [('pirate', 'NOUN'),\n","      ('manager', 'NOUN'),\n","      ('danny', 'NOUN'),\n","      ('murtaugh', 'NOUN'),\n","      ('said', 'VERB'),\n","      ('he', 'PRON'),\n","      (\"hadn't\", 'VERB'),\n","      ('decided', 'VERB'),\n","      .\n","      .\n","      .\n","\n","After running the evaluations, print the conlleval results and Confusion Matrix **for each model** and address the following questions:\n","\n","- Which model showed the best performance?\n","- Was there a noticeable difference between using LidstoneProbDist with gamma set to 0.01 and 0.1?\n","- How did the 'pure' HMM fare in terms of performance?\n","- Was there any significant difference between the 'pure' HMM and the MLE-based model? What can you infer by comparing these two models?\n","- Which of the models performed better with the 'X' tag?\n","- Which other models have you trained? How did they perform?\n","\n","Initiate a conversation with your peers and GAs on the Brightspace forum about these topics, while ensuring you don't give away answers or code\n"]},{"cell_type":"code","execution_count":null,"id":"d84de0e4-5c03-4198-b302-a00b6bfcd0ca","metadata":{"execution":{"iopub.execute_input":"2023-11-23T01:44:53.351189Z","iopub.status.busy":"2023-11-23T01:44:53.351189Z","iopub.status.idle":"2023-11-23T01:44:53.367555Z","shell.execute_reply":"2023-11-23T01:44:53.367190Z","shell.execute_reply.started":"2023-11-23T01:44:53.351189Z"},"tags":[],"id":"d84de0e4-5c03-4198-b302-a00b6bfcd0ca"},"outputs":[],"source":["from nltk.metrics import ConfusionMatrix\n","import itertools\n","\n","def printConfusionMatrix(labels_predicted, labels_correct):\n","    actual_tags = list(itertools.chain(*[[tag for word, tag in sent] for sent in labels_correct]))\n","    predicted_tags = list(itertools.chain(*[[tag for word, tag in sent] for sent in labels_predicted]))\n","    conf_matrix = ConfusionMatrix(actual_tags, predicted_tags)\n","    print(conf_matrix)\n"]},{"cell_type":"code","execution_count":null,"id":"00b2a831-cb97-4e85-b6fa-8de74718f772","metadata":{"execution":{"iopub.execute_input":"2023-11-23T01:44:54.290373Z","iopub.status.busy":"2023-11-23T01:44:54.290373Z","iopub.status.idle":"2023-11-23T01:44:54.317742Z","shell.execute_reply":"2023-11-23T01:44:54.314901Z","shell.execute_reply.started":"2023-11-23T01:44:54.290373Z"},"tags":[],"id":"00b2a831-cb97-4e85-b6fa-8de74718f772"},"outputs":[],"source":["# Importing necessary libraries for model evaluation and metrics calculation\n","from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n","from sklearn.preprocessing import LabelBinarizer\n","from itertools import chain\n","import numpy as np\n","\n","# Defining the conlleval function for evaluating NLP models\n","def printConlleval(labels_predicted, labels_correct):\n","    lb = LabelBinarizer() # Initializing the LabelBinarizer for handling label encoding\n","\n","    # Flattening the list of labels for correct and predicted\n","    labels_correct_flattened = [(word, tag) for sent in labels_correct for word, tag in sent]\n","    labels_predicted_flattened = [(word, tag) for sent in labels_predicted for word, tag in list(sent)]\n","\n","    # Transforming the labels into a binary format for evaluation\n","    y_true_combined = lb.fit_transform([tag for _, tag in labels_correct_flattened])\n","    y_pred_combined = lb.transform([tag for _, tag in labels_predicted_flattened])\n","\n","    tagset = set(lb.classes_)\n","    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n","    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n","\n","    num_sentences = len(labels_predicted)\n","    total_tokens = sum(len(s) for s in labels_predicted)\n","\n","    num_correct_sentences, total_correct_tokens = 0, 0\n","    for pred, true in zip(labels_predicted, labels_correct):\n","        if len(pred) == len(true):\n","            correct_tokens = sum(p == t for p, t in zip(pred, true))\n","            total_correct_tokens += correct_tokens\n","            if correct_tokens == len(pred):\n","                num_correct_sentences += 1\n","\n","    correct_sentences_percentage = num_correct_sentences / num_sentences * 100\n","    total_correct_tokens_percentage = total_correct_tokens / total_tokens * 100\n","\n","    classification_report_dict = classification_report(\n","        y_true_combined,\n","        y_pred_combined,\n","        labels=[class_indices[cls] for cls in tagset],\n","        target_names=tagset,\n","        output_dict=True,\n","        zero_division=1\n","    )\n","\n","\n","    classification_report_dict.pop('macro avg', None)\n","    classification_report_dict.pop('weighted avg', None)\n","    classification_report_dict.pop('samples avg', None)\n","    classification_report_dict.pop('micro avg', None)\n","\n","    total_precision = precision_score(y_true_combined, y_pred_combined, average='weighted', zero_division=1)\n","    total_recall = recall_score(y_true_combined, y_pred_combined, average='weighted', zero_division=1)\n","    total_f1 = f1_score(y_true_combined, y_pred_combined, average='weighted', zero_division=1)\n","    total_line = f\"{'Total':<15s} {total_precision:<10.2f} {total_recall:<10.2f} {total_f1:<10.2f}\"\n","\n","    report_lines = [f\"{k:<15s} {classification_report_dict[k]['precision']:<10.2f} {classification_report_dict[k]['recall']:<10.2f} {classification_report_dict[k]['f1-score']:<10.2f}\" for k in classification_report_dict if isinstance(classification_report_dict[k], dict)]\n","    report_lines.insert(0, \"\\n\")\n","    report_lines.insert(1, f\"{'TAG':<15s} {'Precision':<10s} {'Recall':<10s} {'F1-score':<10s}\\n\")\n","    report_lines.insert(2, total_line)\n","    report_lines.insert(3, '-'*50 + '\\n')\n","    classification_report_str = \"\\n\".join(report_lines)\n","\n","    additional_info_str = ''\n","    additional_info_str += f'Total tokens: {total_tokens}\\n'\n","    additional_info_str += f'Total correct tokens: {total_correct_tokens} ({total_correct_tokens_percentage:.2f}%)\\n'\n","    additional_info_str += f'Processed sentences: {num_sentences}\\n'\n","    additional_info_str += f'Completely correct sentences: {num_correct_sentences} ({correct_sentences_percentage:.2f}%)\\n'\n","\n","    print(additional_info_str + classification_report_str)"]},{"cell_type":"code","execution_count":null,"id":"3bde1948-0d1c-4412-9571-0bed92aca0b1","metadata":{"execution":{"iopub.execute_input":"2023-11-23T01:50:01.111347Z","iopub.status.busy":"2023-11-23T01:50:01.110359Z","iopub.status.idle":"2023-11-23T01:50:01.129353Z","shell.execute_reply":"2023-11-23T01:50:01.128345Z","shell.execute_reply.started":"2023-11-23T01:50:01.111347Z"},"tags":[],"id":"3bde1948-0d1c-4412-9571-0bed92aca0b1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716602518110,"user_tz":300,"elapsed":594,"user":{"displayName":"Blake Pritchard","userId":"04857546906785525811"}},"outputId":"eb20cb05-96ce-4181-f92a-388ae8658255"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total tokens: 40434\n","Total correct tokens: 21330 (52.75%)\n","Processed sentences: 1875\n","Completely correct sentences: 489 (26.08%)\n","\n","\n","TAG             Precision  Recall     F1-score  \n","\n","Total           0.94       0.53       0.65      \n","--------------------------------------------------\n","\n",".               1.00       0.45       0.62      \n","ADJ             0.93       0.47       0.62      \n","ADP             0.97       0.51       0.67      \n","ADV             0.89       0.54       0.67      \n","CONJ            0.06       1.00       0.11      \n","DET             1.00       0.59       0.74      \n","NOUN            0.97       0.47       0.64      \n","NUM             0.98       0.53       0.69      \n","PRON            0.96       0.67       0.79      \n","PRT             0.89       0.53       0.67      \n","VERB            0.98       0.55       0.71      \n","X               1.00       0.28       0.43      \n","     |                        C         N         P         V      |\n","     |         A    A    A    O    D    O    N    R    P    E      |\n","     |         D    D    D    N    E    U    U    O    R    R      |\n","     |    .    J    P    V    J    T    N    M    N    T    B    X |\n","-----+-------------------------------------------------------------+\n","   . |<2152>   .    .    . 2659    .    .    .    .    .    .    . |\n"," ADJ |    .<1444>   .   58 1545    .   36    .    .    3    5    . |\n"," ADP |    .    .<2557>  41 2307    4    1    .   11   43    5    . |\n"," ADV |    .   44   31 <946> 709    2    1    .    .   13    1    . |\n","CONJ |    .    .    .    .<1168>   1    .    .    .    .    .    . |\n"," DET |    .    .   13    3 1855<2769>   7    .   25    .    .    . |\n","NOUN |    1   51    1    2 5681    1<5247>   8    1    .   60    . |\n"," NUM |    .    .    .    .  316    .    2 <364>   .    .    .    . |\n","PRON |    .    .    6    .  416    3    1    . <849>   .    .    . |\n"," PRT |    .    2   39    3  391    .    1    .    . <499>   2    . |\n","VERB |    .   11    1    4 2558    .   98    .    .    .<3327>   . |\n","   X |    .    .    .    .   17    1    2    .    .    .    1   <8>|\n","-----+-------------------------------------------------------------+\n","(row = reference; col = test)\n","\n"]}],"source":["labels_predicted_pure_hmm = [[(sample, label) for sample, label in zip(sample_sentence, label_sentence)] for sample_sentence, label_sentence in zip(test_sentences, predicted_tags_pure_hmm)]\n","\n","printConlleval(labels_predicted_pure_hmm, test_data)\n","printConfusionMatrix(labels_predicted_pure_hmm, test_data)"]},{"cell_type":"code","source":["labels_predicted_hmm_001 = [[(sample, label) for sample, label in zip(sample_sentence, label_sentence)] for sample_sentence, label_sentence in zip(test_sentences, predicted_tags_hmm_001)]\n","\n","printConlleval(labels_predicted_hmm_001, test_data)\n","printConfusionMatrix(labels_predicted_hmm_001, test_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V3L45oCTQXM4","executionInfo":{"status":"ok","timestamp":1716602246147,"user_tz":300,"elapsed":1004,"user":{"displayName":"Blake Pritchard","userId":"04857546906785525811"}},"outputId":"a480c896-acc1-4900-dcb3-249cb164bf50"},"id":"V3L45oCTQXM4","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total tokens: 40434\n","Total correct tokens: 37268 (92.17%)\n","Processed sentences: 1875\n","Completely correct sentences: 585 (31.20%)\n","\n","\n","TAG             Precision  Recall     F1-score  \n","\n","Total           0.94       0.92       0.93      \n","--------------------------------------------------\n","\n",".               0.96       0.99       0.98      \n","ADJ             0.88       0.85       0.87      \n","ADP             0.95       0.97       0.96      \n","ADV             0.81       0.86       0.84      \n","CONJ            0.88       1.00       0.93      \n","DET             0.96       0.99       0.97      \n","NOUN            0.97       0.87       0.92      \n","NUM             0.78       0.89       0.83      \n","PRON            0.91       0.98       0.95      \n","PRT             0.85       0.90       0.87      \n","VERB            0.97       0.90       0.93      \n","X               0.03       0.83       0.06      \n","     |                        C         N         P         V      |\n","     |         A    A    A    O    D    O    N    R    P    E      |\n","     |         D    D    D    N    E    U    U    O    R    R      |\n","     |    .    J    P    V    J    T    N    M    N    T    B    X |\n","-----+-------------------------------------------------------------+\n","   . |<4779>   .    .    .    .    .    .    .    .    .    .   32 |\n"," ADJ |    8<2635>   3  127   20   31  107   15    3    7   16  119 |\n"," ADP |    .    .<4812>  53    9    6    .    .   17   62    4    6 |\n"," ADV |    5   78   69<1509>   5    9    6    2    5   31    8   20 |\n","CONJ |    .    .    .    .<1165>   2    .    .    .    .    .    2 |\n"," DET |    .    .   22    2    .<4614>   .    .   30    .    .    4 |\n","NOUN |  144  211   11   54   81   78<9627> 143   51   46  140  467 |\n"," NUM |    9    9    1    7    5   21    6 <607>   5    .    .   12 |\n","PRON |    .    .   13    .    .    5    2    .<1253>   .    .    2 |\n"," PRT |    .    4   73    5    .    .    3    .    4 <841>   5    2 |\n","VERB |   34   42   59  102   40   31  173   15    6    3<5402>  92 |\n","   X |    .    .    .    .    .    2    1    .    1    .    1  <24>|\n","-----+-------------------------------------------------------------+\n","(row = reference; col = test)\n","\n"]}]},{"cell_type":"code","source":["labels_predicted_hmm_01 = [[(sample, label) for sample, label in zip(sample_sentence, label_sentence)] for sample_sentence, label_sentence in zip(test_sentences, predicted_tags_hmm_01)]\n","\n","printConlleval(labels_predicted_hmm_01, test_data)\n","printConfusionMatrix(labels_predicted_hmm_01, test_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lLJVIBj2QW3D","executionInfo":{"status":"ok","timestamp":1716602319076,"user_tz":300,"elapsed":843,"user":{"displayName":"Blake Pritchard","userId":"04857546906785525811"}},"outputId":"ee187485-ada0-44c6-e31f-b9c62dc1344b"},"id":"lLJVIBj2QW3D","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total tokens: 40434\n","Total correct tokens: 34957 (86.45%)\n","Processed sentences: 1875\n","Completely correct sentences: 516 (27.52%)\n","\n","\n","TAG             Precision  Recall     F1-score  \n","\n","Total           0.95       0.86       0.90      \n","--------------------------------------------------\n","\n",".               0.98       0.97       0.98      \n","ADJ             0.89       0.77       0.83      \n","ADP             0.95       0.94       0.95      \n","ADV             0.82       0.81       0.82      \n","CONJ            0.94       0.95       0.94      \n","DET             0.97       0.98       0.97      \n","NOUN            0.97       0.76       0.85      \n","NUM             0.79       0.82       0.80      \n","PRON            0.91       0.96       0.94      \n","PRT             0.86       0.87       0.87      \n","VERB            0.97       0.85       0.91      \n","X               0.01       0.93       0.02      \n","     |                        C         N         P         V      |\n","     |         A    A    A    O    D    O    N    R    P    E      |\n","     |         D    D    D    N    E    U    U    O    R    R      |\n","     |    .    J    P    V    J    T    N    M    N    T    B    X |\n","-----+-------------------------------------------------------------+\n","   . |<4678>   .    .    .    .    .    .    .    .    .    .  133 |\n"," ADJ |    5<2388>   3  117   10   19   73   13    3    6   15  439 |\n"," ADP |    .    .<4687>  50    6    7    .    .   15   63    4  137 |\n"," ADV |    1   75   69<1418>   4    8    6    2    4   28    5  127 |\n","CONJ |    .    .    .    .<1113>   1    .    .    .    .    .   55 |\n"," DET |    .    .   22    2    .<4564>   .    .   29    .    .   55 |\n","NOUN |   56  156   15   36   32   55<8386> 122   61   35  120 1979 |\n"," NUM |    2    9    .    6    1   15    4 <559>   3    .    1   82 |\n","PRON |    .    .   15    .    .    6    1    .<1230>   .    .   23 |\n"," PRT |    .    3   68    5    .    .    4    .    4 <819>   5   29 |\n","VERB |   16   54   50   88   23   45  134   15    5    2<5088> 479 |\n","   X |    .    .    .    .    .    1    .    .    1    .    .  <27>|\n","-----+-------------------------------------------------------------+\n","(row = reference; col = test)\n","\n"]}]},{"cell_type":"code","source":["labels_predicted_hmm_mle = [[(sample, label) for sample, label in zip(sample_sentence, label_sentence)] for sample_sentence, label_sentence in zip(test_sentences, predicted_tags_hmm_mle)]\n","\n","printConlleval(labels_predicted_hmm_mle, test_data)\n","printConfusionMatrix(labels_predicted_hmm_mle, test_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wjMzQSPveMoH","executionInfo":{"status":"ok","timestamp":1716602367022,"user_tz":300,"elapsed":743,"user":{"displayName":"Blake Pritchard","userId":"04857546906785525811"}},"outputId":"15c6f085-e364-4dfe-f7db-3da94b77e2ca"},"id":"wjMzQSPveMoH","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total tokens: 40434\n","Total correct tokens: 21330 (52.75%)\n","Processed sentences: 1875\n","Completely correct sentences: 489 (26.08%)\n","\n","\n","TAG             Precision  Recall     F1-score  \n","\n","Total           0.94       0.53       0.65      \n","--------------------------------------------------\n","\n",".               1.00       0.45       0.62      \n","ADJ             0.93       0.47       0.62      \n","ADP             0.97       0.51       0.67      \n","ADV             0.89       0.54       0.67      \n","CONJ            0.06       1.00       0.11      \n","DET             1.00       0.59       0.74      \n","NOUN            0.97       0.47       0.64      \n","NUM             0.98       0.53       0.69      \n","PRON            0.96       0.67       0.79      \n","PRT             0.89       0.53       0.67      \n","VERB            0.98       0.55       0.71      \n","X               1.00       0.28       0.43      \n","     |                        C         N         P         V      |\n","     |         A    A    A    O    D    O    N    R    P    E      |\n","     |         D    D    D    N    E    U    U    O    R    R      |\n","     |    .    J    P    V    J    T    N    M    N    T    B    X |\n","-----+-------------------------------------------------------------+\n","   . |<2152>   .    .    . 2659    .    .    .    .    .    .    . |\n"," ADJ |    .<1444>   .   58 1545    .   36    .    .    3    5    . |\n"," ADP |    .    .<2557>  41 2307    4    1    .   11   43    5    . |\n"," ADV |    .   44   31 <946> 709    2    1    .    .   13    1    . |\n","CONJ |    .    .    .    .<1168>   1    .    .    .    .    .    . |\n"," DET |    .    .   13    3 1855<2769>   7    .   25    .    .    . |\n","NOUN |    1   51    1    2 5681    1<5247>   8    1    .   60    . |\n"," NUM |    .    .    .    .  316    .    2 <364>   .    .    .    . |\n","PRON |    .    .    6    .  416    3    1    . <849>   .    .    . |\n"," PRT |    .    2   39    3  391    .    1    .    . <499>   2    . |\n","VERB |    .   11    1    4 2558    .   98    .    .    .<3327>   . |\n","   X |    .    .    .    .   17    1    2    .    .    .    1   <8>|\n","-----+-------------------------------------------------------------+\n","(row = reference; col = test)\n","\n"]}]},{"cell_type":"code","source":["labels_predicted_hmm_ele = [[(sample, label) for sample, label in zip(sample_sentence, label_sentence)] for sample_sentence, label_sentence in zip(test_sentences, predicted_tags_hmm_ele)]\n","\n","printConlleval(labels_predicted_hmm_ele, test_data)\n","printConfusionMatrix(labels_predicted_hmm_ele, test_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CIVkR8pxQWl8","executionInfo":{"status":"ok","timestamp":1716602418420,"user_tz":300,"elapsed":675,"user":{"displayName":"Blake Pritchard","userId":"04857546906785525811"}},"outputId":"876d1324-af5c-49aa-883b-628d2f63e92c"},"id":"CIVkR8pxQWl8","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total tokens: 40434\n","Total correct tokens: 26037 (64.39%)\n","Processed sentences: 1875\n","Completely correct sentences: 262 (13.97%)\n","\n","\n","TAG             Precision  Recall     F1-score  \n","\n","Total           0.95       0.64       0.75      \n","--------------------------------------------------\n","\n",".               1.00       0.89       0.94      \n","ADJ             0.89       0.45       0.60      \n","ADP             0.95       0.74       0.83      \n","ADV             0.83       0.58       0.68      \n","CONJ            0.96       0.75       0.84      \n","DET             0.98       0.89       0.93      \n","NOUN            0.98       0.45       0.61      \n","NUM             0.80       0.48       0.60      \n","PRON            0.87       0.83       0.85      \n","PRT             0.88       0.72       0.79      \n","VERB            0.98       0.60       0.74      \n","X               0.00       0.97       0.00      \n","     |                        C         N         P         V      |\n","     |         A    A    A    O    D    O    N    R    P    E      |\n","     |         D    D    D    N    E    U    U    O    R    R      |\n","     |    .    J    P    V    J    T    N    M    N    T    B    X |\n","-----+-------------------------------------------------------------+\n","   . |<4278>   .    .    .    .    .    .    .    .    .    .  533 |\n"," ADJ |    1<1388>   5   93    5    7   36    7    2    2   16 1529 |\n"," ADP |    .    .<3685>  35    3   12    .    .   14   55    4 1161 |\n"," ADV |    .   41   53<1012>   1    7    3    2    5   23    4  596 |\n","CONJ |    .    .    .    . <880>   .    .    .    .    .    .  289 |\n"," DET |    .    .   21    2    .<4169>   .    .   26    .    .  454 |\n","NOUN |   13   90   15   23   13   39<4936>  61  103   13   50 5697 |\n"," NUM |    1    5    3    2    .    1    1 <330>   .    .    .  339 |\n","PRON |    .    .    6    .    .    4    1    .<1064>   .    .  200 |\n"," PRT |    .    .   55    5    .    .    1    .    5 <674>   5  192 |\n","VERB |    6   30   35   50   13   24   62   14    6    2<3593>2164 |\n","   X |    .    .    .    .    .    .    .    .    1    .    .  <28>|\n","-----+-------------------------------------------------------------+\n","(row = reference; col = test)\n","\n"]}]},{"cell_type":"markdown","id":"48e5e5b6-508d-4741-a764-2454c1edf025","metadata":{"id":"48e5e5b6-508d-4741-a764-2454c1edf025"},"source":["## Choose your best model\n","\n","Choose your best model and export it using the 'dill' library. You can locate the exported file in the same folder as your notebook. Make sure to submit it to Codegrade. And remember, don't change the final file name of the model - it should remain 'mybestmodel.dill'."]},{"cell_type":"markdown","source":[],"metadata":{"id":"u7pyM0PUNSjo"},"id":"u7pyM0PUNSjo"},{"cell_type":"code","source":["#from google.colab import drive\n","#drive.mount('/content/drive')\n","#drive_path = \"/content/drive/MyDrive/School/Eastern University/DTSC/DTSC_685/Module_4/Assignment_3/Hidden_Markov_Model_Viterbi_NLP/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ppFb295dgBCo","executionInfo":{"status":"ok","timestamp":1716602940641,"user_tz":300,"elapsed":24215,"user":{"displayName":"Blake Pritchard","userId":"04857546906785525811"}},"outputId":"53459eb8-a29d-455e-bbb1-b3790a000e4d"},"id":"ppFb295dgBCo","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"id":"18a285a5-c694-47af-94f1-49074d150a53","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:45:46.707970Z","iopub.status.idle":"2023-11-23T00:45:46.707970Z","shell.execute_reply":"2023-11-23T00:45:46.707970Z","shell.execute_reply.started":"2023-11-23T00:45:46.707970Z"},"tags":[],"id":"18a285a5-c694-47af-94f1-49074d150a53"},"outputs":[],"source":["# Importing dill library for model serialization\n","# import dill\n","mybestmodel = hmm_001\n","\n","# serialization with dill\n","with open(drive_path + 'mybestmodel.dill', 'wb') as file:\n","    dill.dump(mybestmodel, file)"]},{"cell_type":"markdown","id":"b17e4248-c571-4646-94d6-1bbd2a3a11a2","metadata":{"id":"b17e4248-c571-4646-94d6-1bbd2a3a11a2"},"source":["This material is for enrolled students' academic use only and protected under U.S. Copyright Laws. This content must not be shared outside the confines of this course, in line with Eastern University's academic integrity policies. Unauthorized reproduction, distribution, or transmission of this material, including but not limited to posting on third-party platforms like GitHub, is strictly prohibited and may lead to disciplinary action. You may not alter or remove any copyright or other notice from copies of any content taken from BrightSpace or Eastern University’s website.\n","\n","© Copyright Notice 2024, Eastern University - All Rights Reserved"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}